{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10430a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:42:34.282725Z",
     "iopub.status.busy": "2023-05-26T07:42:34.281827Z",
     "iopub.status.idle": "2023-05-26T07:42:34.472853Z",
     "shell.execute_reply": "2023-05-26T07:42:34.471879Z"
    },
    "papermill": {
     "duration": 0.200938,
     "end_time": "2023-05-26T07:42:34.475804",
     "exception": false,
     "start_time": "2023-05-26T07:42:34.274866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ad330a4",
   "metadata": {},
   "source": [
    "### DataLoader & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e9eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:42:34.500079Z",
     "iopub.status.busy": "2023-05-26T07:42:34.499322Z",
     "iopub.status.idle": "2023-05-26T07:44:37.501130Z",
     "shell.execute_reply": "2023-05-26T07:44:37.499695Z"
    },
    "papermill": {
     "duration": 123.012259,
     "end_time": "2023-05-26T07:44:37.504720",
     "exception": false,
     "start_time": "2023-05-26T07:42:34.492461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes={ \n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'fqid':'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    \n",
    "    'page':'category',\n",
    "    'room_coor_x':np.float32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "\n",
    "    'elapsed_time':np.int32,\n",
    "    'text':'category',\n",
    "    'level':np.uint8,\n",
    "    'fullscreen':'category',\n",
    "    'hq':'category',\n",
    "    'music':'category',\n",
    "    'level_group':'category'\n",
    "}\n",
    "\n",
    "train=pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aea8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:44:37.518105Z",
     "iopub.status.busy": "2023-05-26T07:44:37.517230Z",
     "iopub.status.idle": "2023-05-26T07:45:27.771455Z",
     "shell.execute_reply": "2023-05-26T07:45:27.770306Z"
    },
    "papermill": {
     "duration": 50.272682,
     "end_time": "2023-05-26T07:45:27.783204",
     "exception": false,
     "start_time": "2023-05-26T07:44:37.510522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a column operation list to preprocess data after reading the CSV file\n",
    "columns = [\n",
    "    # Calculate the difference value of the 'elapsed_time' column (the difference between the current row and the previous row), fill missing values with 0, and then restrict the result within the range [0, 1e9]\n",
    "    # Finally, group the results by 'session_id' and 'level' columns\n",
    "    (\n",
    "        (pl.col('elapsed_time') - pl.col('elapsed_time').shift(1))\n",
    "        .fill_null(0)\n",
    "        .clip(0, 1e9)\n",
    "        .over(['session_id', 'level'])\n",
    "        .alias('elapsed_time_diff')\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        (pl.col('screen_coor_x') - pl.col('screen_coor_x').shift(1))\n",
    "        .abs().\n",
    "        over(['session_id', 'level'])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        (pl.col(\"screen_coor_y\") - pl.col(\"screen_coor_y\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        (pl.col('room_coor_x') - pl.col('room_coor_x').shift(1))\n",
    "        .abs().\n",
    "        over(['session_id', 'level'])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        (pl.col(\"room_coor_y\") - pl.col(\"room_coor_y\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "\n",
    "    pl.col(\"fqid\").fill_null(\"fqid_None\"),\n",
    "    pl.col(\"text_fqid\").fill_null(\"text_fqid_None\")\n",
    "]\n",
    "\n",
    "train = pl.from_pandas(train).drop(['fullscreen', 'hq', 'music']).with_columns(columns)\n",
    "\n",
    "fqid_lists = list(train['fqid'].unique())\n",
    "text_fqid_lists = list(train['text_fqid'].unique())\n",
    "room_fqid_lists = list(train['room_fqid'].unique())\n",
    "name_feature_lists = list(train['name'].unique())\n",
    "event_name_feature_lists = list(train['event_name'].unique())\n",
    "levels = list(train['level'].unique())\n",
    "level_groups = list(train['level_group'].unique())\n",
    "\n",
    "print(levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset based on level_group, corresponding to the three question checkpoints in the game\n",
    "df1 = train.filter(pl.col(\"level_group\") == '0-4')\n",
    "df2 = train.filter(pl.col(\"level_group\") == '5-12')\n",
    "df3 = train.filter(pl.col(\"level_group\") == '13-22')\n",
    "\n",
    "print(df1.shape, df2.shape, df3.shape)\n",
    "\n",
    "# Delete the original training set to free up memory\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Feature\n",
    "category = [\n",
    "    'event_name', 'name', 'fqid', 'room_fqid', 'text_fqid'\n",
    "]\n",
    "\n",
    "# Value Feature\n",
    "numeric = [\n",
    "    'page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "    'hover_duration', 'elapsed_time_diff'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "208d0ab8",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bca13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:45:27.797053Z",
     "iopub.status.busy": "2023-05-26T07:45:27.796237Z",
     "iopub.status.idle": "2023-05-26T07:45:27.829282Z",
     "shell.execute_reply": "2023-05-26T07:45:27.828227Z"
    },
    "papermill": {
     "duration": 0.04344,
     "end_time": "2023-05-26T07:45:27.832057",
     "exception": false,
     "start_time": "2023-05-26T07:45:27.788617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def elapsed_diff_agg(column, column_value_list, feature_suffix):\n",
    "    elapsed_agg = [\n",
    "        *[pl.col(column).filter(pl.col(column) == c).count().alias(f\"{c}_{column}_counts_{feature_suffix}\") for c in column_value_list],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(column) == c).std().alias(f\"{c}_{column}_elapsed_std_{feature_suffix}\") for c in column_value_list],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(column) == c).mean().alias(f\"{c}_{column}_elapsed_mean_{feature_suffix}\") for c in column_value_list],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(column) == c).max().alias(f\"{c}_{column}_elapsed_max_{feature_suffix}\") for c in column_value_list],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(column) == c).min().alias(f\"{c}_{column}_elapsed_min_{feature_suffix}\") for c in column_value_list],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(column) == c).sum().alias(f\"{c}_{column}_elapsed_sum_{feature_suffix}\") for c in column_value_list], \n",
    "    ]\n",
    "    return elapsed_agg\n",
    "\n",
    "def feature_engineer(x, grp, feature_suffix):\n",
    "    \"\"\"\n",
    "    This function is used for feature engineering, including the calculation of statistical features and the construction of specific features based on business logic.\n",
    "\n",
    "    Parameters:\n",
    "    x: The input data\n",
    "    grp: The level of the data, used to construct different features according to different levels\n",
    "    feature_suffix: The feature suffix, used to distinguish features of different levels\n",
    "    \"\"\"\n",
    "    aggs = [\n",
    "        pl.col('index').count().alias(f\"session_number_{feature_suffix}\"),\n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique_{feature_suffix}\") for c in category],\n",
    "        *[pl.col(c).std().alias(f\"{c}_std_{feature_suffix}\") for c in numeric],\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean_{feature_suffix}\") for c in numeric],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min_{feature_suffix}\") for c in numeric],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max_{feature_suffix}\") for c in numeric],\n",
    "        *[pl.col(c).sum().alias(f\"{c}_sum_{feature_suffix}\") for c in numeric],\n",
    "    ]\n",
    "\n",
    "    aggs.extend(elapsed_diff_agg('fqid', fqid_lists, feature_suffix))\n",
    "    aggs.extend(elapsed_diff_agg('text_fqid', text_fqid_lists, feature_suffix))\n",
    "    aggs.extend(elapsed_diff_agg('room_fqid', room_fqid_lists, feature_suffix))\n",
    "    aggs.extend(elapsed_diff_agg('name', name_feature_lists, feature_suffix))\n",
    "    aggs.extend(elapsed_diff_agg('event_name', event_name_feature_lists, feature_suffix))\n",
    "    aggs.extend(elapsed_diff_agg('level', levels, feature_suffix))\n",
    "    aggs.extend(elapsed_diff_agg('level_group', level_groups, feature_suffix))\n",
    "\n",
    "    df = x.groupby(['session_id'], maintain_order=True).agg(aggs).sort('session_id')\n",
    "    \n",
    "\n",
    "    if grp == '5-12':\n",
    "        aggs = [\n",
    "            pl.col(\"elapsed_time\").filter((pl.col(\"text\")==\"Here's the log book.\") |(pl.col(\"fqid\")=='logbook.page.bingo')).apply(lambda s: s.max()-s.min()).alias(\"logbook_bingo_duration\"),\n",
    "\n",
    "            pl.col(\"index\").filter((pl.col(\"text\") == \"Here's the log book.\") | (pl.col(\"fqid\") == 'logbook.page.bingo')).apply(lambda s: s.max() - s.min()).alias(\"logbook_bingo_indexCount\"),\n",
    "\n",
    "            pl.col(\"elapsed_time\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\"reader_bingo_duration\"),\n",
    "\n",
    "            pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\"reader_bingo_indexCount\"),\n",
    "\n",
    "            pl.col(\"elapsed_time\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\"journals_bingo_duration\"),\n",
    "\n",
    "            pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\"journals_bingo_indexCount\"),\n",
    "        ]\n",
    "        tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "        df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "    if grp == '13-22':\n",
    "        aggs = [\n",
    "            pl.col(\"elapsed_time\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_duration\"),\n",
    "\n",
    "            pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_indexCount\"),\n",
    "\n",
    "            pl.col(\"elapsed_time\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_duration\"),\n",
    "\n",
    "            pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_indexCount\")\n",
    "        ]\n",
    "        tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "        df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "    return df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77a0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:45:32.534031Z",
     "iopub.status.busy": "2023-05-26T07:45:32.533020Z",
     "iopub.status.idle": "2023-05-26T07:46:28.506290Z",
     "shell.execute_reply": "2023-05-26T07:46:28.504930Z"
    },
    "papermill": {
     "duration": 55.983819,
     "end_time": "2023-05-26T07:46:28.509550",
     "exception": false,
     "start_time": "2023-05-26T07:45:32.525731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = feature_engineer(df1, grp='0-4', feature_suffix='xgboost')\n",
    "df1.set_index('session_id')\n",
    "print(df1.shape)\n",
    "\n",
    "df2 = feature_engineer(df2, grp='5-12', feature_suffix='xgboost')\n",
    "df2.set_index('session_id')\n",
    "print(df2.shape)\n",
    "\n",
    "df3 = feature_engineer(df3, grp='13-22', feature_suffix='xgboost')\n",
    "df3.set_index('session_id')\n",
    "print(df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f102973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:46:28.523868Z",
     "iopub.status.busy": "2023-05-26T07:46:28.523377Z",
     "iopub.status.idle": "2023-05-26T07:46:31.421773Z",
     "shell.execute_reply": "2023-05-26T07:46:31.420603Z"
    },
    "papermill": {
     "duration": 2.909244,
     "end_time": "2023-05-26T07:46:31.425014",
     "exception": false,
     "start_time": "2023-05-26T07:46:28.515770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the ratio of missing values in each column for each dataset\n",
    "null1 = df1.isnull().sum().sort_values(ascending=False) / len(df1)\n",
    "null2 = df2.isnull().sum().sort_values(ascending=False) / len(df1)\n",
    "null3 = df3.isnull().sum().sort_values(ascending=False) / len(df1)\n",
    "\n",
    "# Find the columns where the missing value ratio is greater than 0.9\n",
    "drop1 = list(null1[null1 > 0.9].index)\n",
    "drop2 = list(null2[null2 > 0.9].index)\n",
    "drop3 = list(null3[null3 > 0.9].index)\n",
    "print(len(drop1), len(drop2), len(drop3))\n",
    "\n",
    "for col in df1.columns:\n",
    "    if df1[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop1.append(col)\n",
    "print(\"*********df1 DONE*********\")\n",
    "\n",
    "for col in df2.columns:\n",
    "    if df2[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop2.append(col)\n",
    "print(\"*********df2 DONE*********\")\n",
    "\n",
    "for col in df3.columns:\n",
    "    if df3[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop3.append(col)\n",
    "print(\"*********df3 DONE*********\")\n",
    "\n",
    "features1 = [c for c in df1.columns if c not in drop1 + ['level_group']]\n",
    "features2 = [c for c in df2.columns if c not in drop2 + ['level_group']]\n",
    "features3 = [c for c in df3.columns if c not in drop3 + ['level_group']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0a339d6",
   "metadata": {
    "papermill": {
     "duration": 0.007571,
     "end_time": "2023-05-26T07:46:31.597281",
     "exception": false,
     "start_time": "2023-05-26T07:46:31.589710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d1d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:46:31.615156Z",
     "iopub.status.busy": "2023-05-26T07:46:31.614702Z",
     "iopub.status.idle": "2023-05-26T07:46:32.821240Z",
     "shell.execute_reply": "2023-05-26T07:46:32.820066Z"
    },
    "papermill": {
     "duration": 1.219142,
     "end_time": "2023-05-26T07:46:32.824575",
     "exception": false,
     "start_time": "2023-05-26T07:46:31.605433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators_xgb = [498, 448, 378, 364, 405, 495, 456, 249, 384, 405, 356, 262, 484, 381, 392, 248 ,248, 345]\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric':'logloss',\n",
    "    'learning_rate': 0.02,\n",
    "    'alpha': 8,\n",
    "    'max_depth': 4,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'seed': 2023\n",
    "}\n",
    "\n",
    "\n",
    "targets = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train_labels.csv')\n",
    "\n",
    "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba94cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T07:46:32.842237Z",
     "iopub.status.busy": "2023-05-26T07:46:32.841783Z",
     "iopub.status.idle": "2023-05-26T08:00:06.522748Z",
     "shell.execute_reply": "2023-05-26T08:00:06.521749Z"
    },
    "papermill": {
     "duration": 813.701302,
     "end_time": "2023-05-26T08:00:06.533865",
     "exception": false,
     "start_time": "2023-05-26T07:46:32.832563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in range(1, 19):\n",
    "    if t <= 3:\n",
    "        grp = '0-4'\n",
    "        df = df1\n",
    "        features = features1 + [f'pre{i}' for i in range(1, t)]\n",
    "    elif t <= 13:\n",
    "        grp = '5-12'\n",
    "        df = df2\n",
    "        features = features2 + [f'pre{i}' for i in range(4, t)]\n",
    "    else:\n",
    "        grp = '13-22'\n",
    "        df = df3\n",
    "        features = features3 + [f'pre{i}' for i in range(14, t)]\n",
    "\n",
    "    train_users = df['session_id']\n",
    "    train_y = targets.loc[targets.q == t].set_index('session').loc[train_users]\n",
    "\n",
    "    xgb_params['n_estimators'] = estimators_xgb[t-1]\n",
    "\n",
    "    clf =  XGBClassifier(**xgb_params)\n",
    "    clf.fit(df[features].astype('float32'), train_y['correct'], verbose = 0)\n",
    "    df[f'pre{t}'] = clf.predict_proba(df[features].astype('float32'))[:,1]\n",
    "    clf.save_model(f'XGB_question{t}.xgb')\n",
    "    \n",
    "    print(f'model XGB saved for question {t}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67456781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:00:06.583956Z",
     "iopub.status.busy": "2023-05-26T08:00:06.583100Z",
     "iopub.status.idle": "2023-05-26T08:00:06.614428Z",
     "shell.execute_reply": "2023-05-26T08:00:06.613308Z"
    },
    "papermill": {
     "duration": 0.044956,
     "end_time": "2023-05-26T08:00:06.617295",
     "exception": false,
     "start_time": "2023-05-26T08:00:06.572339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede46dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:00:06.638669Z",
     "iopub.status.busy": "2023-05-26T08:00:06.637833Z",
     "iopub.status.idle": "2023-05-26T08:00:09.531871Z",
     "shell.execute_reply": "2023-05-26T08:00:09.530905Z"
    },
    "papermill": {
     "duration": 2.907698,
     "end_time": "2023-05-26T08:00:09.534769",
     "exception": false,
     "start_time": "2023-05-26T08:00:06.627071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for (test, sample_submission) in iter_test:\n",
    "    test = test.sort_values(by = 'index')\n",
    "    session_id = test.session_id.values[0]\n",
    "    grp = test['level_group'].values[0]\n",
    "\n",
    "    a,b = limits[grp]\n",
    "    if a == 1:\n",
    "        features = features1 \n",
    "    elif a == 4:\n",
    "        features = features2\n",
    "    else:\n",
    "        features = features3\n",
    "\n",
    "    test = pl.from_pandas(test).drop(['fullscreen', 'hq', 'music']).with_columns(columns)\n",
    "    test = feature_engineer(test, grp, feature_suffix='xgboost')\n",
    "    features_pre = []\n",
    "\n",
    "    for t in range(a, b):\n",
    "        clf = XGBClassifier()\n",
    "        clf.load_model(f\"/kaggle/working/XGB_question{t}.xgb\")\n",
    "        mask = sample_submission.session_id.str.contains(f'q{t}')\n",
    "        p = clf.predict_proba(test[features+features_pre].astype('float32'))[:, 1]\n",
    "        test[f'pre{t}'] = p\n",
    "        sample_submission.loc[mask, 'correct'] = int((p.item()) > 0.625)\n",
    "        features_pre.append(f'pre{t}')\n",
    "\n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4ceaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:00:09.556110Z",
     "iopub.status.busy": "2023-05-26T08:00:09.555417Z",
     "iopub.status.idle": "2023-05-26T08:00:09.564516Z",
     "shell.execute_reply": "2023-05-26T08:00:09.563561Z"
    },
    "papermill": {
     "duration": 0.022496,
     "end_time": "2023-05-26T08:00:09.567083",
     "exception": false,
     "start_time": "2023-05-26T08:00:09.544587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1067.028345,
   "end_time": "2023-05-26T08:00:10.808456",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-26T07:42:23.780111",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
